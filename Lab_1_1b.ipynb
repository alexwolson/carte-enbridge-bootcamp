{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CARTE-Enbridge Bootcamp\n",
    "#### Lab 1-1b\n",
    "\n",
    "In this lab, we'll delve into:\n",
    "\n",
    "- Working with NumPy and pandas\n",
    "- Data Loading and Cleaning\n",
    "- Basic Data Visualization\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## NumPy and Pandas\n",
    "\n",
    "### NumPy\n",
    "\n",
    "NumPy is a Python library that provides a variety of useful features for working with numerical data.  The most important feature of NumPy is the **NumPy array**, a data structure that (as the name implies) is similar to a Python list, but provides additional features that make it useful for data science.  Let's take a look at some of the advantages NumPy arrays have over Python lists:\n",
    "\n",
    "- **Ease of use:** You can write small, concise, and intuitive mathematical expressions like `X + 2` and `X * Y` (where `X` and `Y` are arrays), and the operations will be performed _element-wise_ (sometimes called _vectorized_).  This means that unlike Python lists, you don't have to write loops in order to make simple mathematical operations!\n",
    "- **Performance:** NumPy arrays are implemented in C under the hood, meaning that operations on large arrays can be orders of magnitude faster than operations on Python lists!\n",
    "- **Useful features:** NumPy provides many convenience functions and methods for performing quick and accurate mathematical operations and conversions on your data.  For example, you can compute the mean and standard deviation of an array using `np.mean()` and `np.std()`, respectively.\n",
    "- **Broad applicability:** NumPy is the base of the entire Python data science ecosystem.  Practically every data science library for Python leverages NumPy in some way, making it a crucial skill to master for data science.\n",
    "\n",
    "#### Creating NumPy Arrays\n",
    "\n",
    "There are a variety of ways to create NumPy arrays, but the easiest way is to convert an existing list using `np.array()`.  Let's create a NumPy array from a list of integers:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "73d93f1d2422d23a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np  # convention, np is the standard alias\n",
    "\n",
    "my_list = [1, 2, 3, 4, 5]\n",
    "my_array = np.array(my_list)\n",
    "\n",
    "print(my_array)\n",
    "print(my_array * 2)\n",
    "print(my_array.sum())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "923c233f0aeaba8d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pandas\n",
    "\n",
    "Pandas is a Python library that provides additional data structures and data manipulation methods that make working with data easier.  The primary data structures in Pandas are **Series** and **DataFrames**.  A **Series** is a one-dimensional array of data where each element is labeled with an index.  A **DataFrame** is a tabular data structure comprised of rows and columns, similar to a spreadsheet, database table, or R's data.frame object.  Pandas is one of the most popular data science libraries for Python, and will be used heavily in this course.\n",
    "\n",
    "One of many convenient features of Pandas is that it can read in just about any tabular data - including CSVs, Excel spreadsheets, and SQL tables - and convert them to DataFrames.  In this example, we will load a CSV from a URL (yes, it can download files too!) and convert it to a DataFrame:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4a9300bcbd87602"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in the CSV file\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/pandas-dev/pandas/main/pandas/tests/io/data/csv/banklist.csv\"\n",
    ")\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33117dbd678114a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can do a lot of convenient things with Pandas DataFrames, such as:\n",
    "\n",
    "- Group rows by their value in a particular column:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "193ed310edb26f4d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get a list of cities (in the City column), grouped by state (in the ST column)\n",
    "for state, cities in df.groupby(\"ST\")[\"City\"]:\n",
    "    print(state)\n",
    "    print(cities.values)\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e30df1dbcc9e45df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Filter rows based on a condition (or multiple conditions):"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3b585a58a3c6682"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get a list of all banks in California that were acquired by U.S. Bank N.A.\n",
    "df[(df[\"ST\"] == \"CA\") & (df[\"Acquiring Institution\"] == \"U.S. Bank N.A.\")]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36139cb459dd7a28"
  },
  {
   "cell_type": "markdown",
   "source": [
    "And lastly for now,\n",
    "- Sort rows by the values in one or more columns:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdc23d2f17aa59fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Sort the DataFrame by the Acquiring Institution column\n",
    "df.sort_values(\"Acquiring Institution\", ascending=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3e7d059b071dd36"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Often when we're working with data, we'll find that it's not in the format we need it to be in.  For example, we might find that some of the values are missing, or that some of the values are in the wrong format.  In this section, we'll learn how to deal with some of these common issues.\n",
    "\n",
    "### Missing Values\n",
    "\n",
    "Missing values are values that are absent from the dataset.  Missing values are common in real-world datasets for a variety of reasons, such as data not being collected properly or data being lost.  Missing values are represented in Pandas by either `NaN` or `None`.  Let's take a look at how we can deal with missing values in Pandas."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7721360e5b0c4b4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    ")\n",
    "\n",
    "# Display the first 5 rows of the DataFrame\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b0207a2f2638842"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This is a famous dataset containing information about the passengers of the Titanic.  We'll come back to it a few times in this course.  For now, let's take a look at the `Age` column.  We can see that some of the values are missing, and are represented by `NaN`.  Let's count how many values are missing:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d57e4e9a1d832770"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Display the number of missing values in the Age column\n",
    "missing_count = df[\"Age\"].isna().sum()\n",
    "print(\n",
    "    f\"There are {missing_count} missing values in the Age column out of {len(df)} total rows.\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4fa6d1f6972d89"
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that there are 177 missing values in the `Age` column.  Later on, we'll learn how to deal with missing values, but for now, let's move on to another common data cleaning task: converting data to the right format.\n",
    "\n",
    "### Data Types\n",
    "\n",
    "Data types are a way of telling the computer how to interpret the data in a column.  For example, the `Age` column in the Titanic dataset is represented as floating-point numbers (i.e. numbers with decimal points).  This makes sense, since a person's age can be represented as a decimal (e.g. 27.5 years old).  However, the `Survived` column is represented as integers (i.e. whole numbers).  This also makes sense, since a person can either survive (1) or not survive (0).  Let's take a look at the data types of each column:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb9f8949737e62d5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7f4099a021b76d1d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "You may notice that a few of the columns are represented as `object`.  This is Pandas's way of saying that it doesn't know what data type to use.  In this case, it's because the values in those columns are strings, and Pandas doesn't know how to convert them to a numeric data type.  Let's take a look at the `Sex` column:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "28f2edee4845a3b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Sex\"]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a1ddedb2af88d04"
  },
  {
   "cell_type": "markdown",
   "source": [
    "While it might make sense for this column to contain `male` and `female` when a person is looking at it, when we're doing data science it's much easier for this column to contain a number. There are a few ways to do this, and we will look at some of the others later. For now, let's create a new column called `is_female` which has a value of `True` when the passenger is a female, and `False` otherwise:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d0ff71ed5d5ca18b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"is_female\"] = df[\"Sex\"] == \"female\"\n",
    "df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8b1df04d69f426c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you look at the last column, you'll see that we have added our new column that only contains `True` or `False`. Why does this benefit us? For one thing, it allows us to easily do mathematical operations directly on the data. Let's say we want to count how many women were on the ship. If we try to take the sum of the `Sex` column, we get the following:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "594a808684dc70b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Sex\"].sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d226aefc1c8033e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Clearly that's totally useless! Let's try the same with our new `is_female` column:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cd86229b61faa519"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"is_female\"].sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2de41e7917728cb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Much more convenient! We can even calculate the percentage of passengers who were women in a single line now:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3555255440a44d56"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"is_female\"].mean() * 100"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8081faaaac1d40d7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Another benefit is to do with how much storage our data takes up. Let's compare the memory usage of our two columns:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "95bdaddbac875eb5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "memory_usage_sex = df[\"Sex\"].memory_usage(deep=True)\n",
    "memory_usage_is_female = df[\"is_female\"].memory_usage(deep=True)\n",
    "print(f\"Sex column memory usage: {memory_usage_sex} bytes\")\n",
    "print(f\"is_female column memory usage: {memory_usage_is_female} bytes\")\n",
    "print(f\"Sex column uses {memory_usage_sex/memory_usage_is_female:.2f} times more data\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9474602d872ffde"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Visualization\n",
    "\n",
    "Data visualization turns complex datasets into easily digestible visuals, making it quicker to spot underlying patterns. Let's say we are interested in the relationship between cabin class and survival rate. We can use a bar chart to visualize this relationship:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdd257171dc532c7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Standard convention - matplotlib's pyplot is usually aliased as plt"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "457628f11f2c5d09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the number of survivors and fatalities for each cabin class\n",
    "survivors = df.groupby(\"Pclass\")[\"Survived\"].sum()\n",
    "fatalities = df.groupby(\"Pclass\")[\"Survived\"].count() - survivors\n",
    "\n",
    "# Create a bar chart\n",
    "plt.bar(survivors.index, survivors.values, label=\"Survived\")\n",
    "plt.bar(fatalities.index, fatalities.values, bottom=survivors.values, label=\"Died\")\n",
    "\n",
    "# Add labels and a legend\n",
    "plt.xlabel(\"Cabin Class\")\n",
    "plt.ylabel(\"Number of Passengers\")\n",
    "plt.legend()\n",
    "\n",
    "# Display the chart\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55fb2b94a5fcef"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Thanks to our visualization, we can easily see that the survival rate was highest for passengers in first class, and lowest for passengers in third class.  We can also see that there were more fatalities than survivors in third class, but more survivors than fatalities in first and second class. This is just one example of how data visualization can help us understand our data.\n",
    "\n",
    "## Optional Exercise: Data Visualization\n",
    "\n",
    "In this exercise, you will create a visualization to answer the following question:\n",
    "\n",
    "> What was the survival rate by title?\n",
    "\n",
    "We have provided the code to extract the title from each passenger's name, and to create a new column called `Title` containing the title for each passenger.  You will need to create a visualization to answer the question above.  You can use any type of visualization you like, but we recommend a bar chart or a pie chart.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ee259a5a9b2ae5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\"Title\"] = df[\"Name\"].str.extract(\n",
    "    \" ([A-Za-z]+)\\.\", expand=False\n",
    ")  # This is a Regular Expression - a way of extracting patterns from text"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fc03667c96a7cd3b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df[\n",
    "    \"Title\"\n",
    "].value_counts()  # You might notice the title Jonkheer - this is a Dutch honorific title, the lowest in the Dutch nobility system"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c054ea1e2e8aebc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "### Your answer here"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc807e11716209bf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
